{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analisi Frequenza Risultati\n",
                "Questo notebook analizza la distribuzione dei risultati delle partite salvate nel database."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Installazione LLM\n",
                "Esegui questa cella per installare le dipendenze necessarie per l'uso del LLM (Large Language Model)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: llama-cpp-python in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (0.3.16)\n",
                        "Requirement already satisfied: langchain in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (1.2.8)\n",
                        "Requirement already satisfied: langchain-community in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (0.4.1)\n",
                        "Requirement already satisfied: langchain-experimental in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (0.4.1)\n",
                        "Requirement already satisfied: sqlalchemy in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (2.0.46)\n",
                        "Requirement already satisfied: huggingface-hub in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (1.3.7)\n",
                        "Requirement already satisfied: langchain-core in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (1.2.8)\n",
                        "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from llama-cpp-python) (4.15.0)\n",
                        "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from llama-cpp-python) (2.4.2)\n",
                        "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
                        "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from llama-cpp-python) (3.1.6)\n",
                        "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain) (1.0.7)\n",
                        "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain) (2.12.5)\n",
                        "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (1.0.1)\n",
                        "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (2.32.5)\n",
                        "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (6.0.3)\n",
                        "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (3.13.3)\n",
                        "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
                        "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
                        "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
                        "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (0.6.8)\n",
                        "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
                        "Requirement already satisfied: greenlet>=1 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from sqlalchemy) (3.3.1)\n",
                        "Requirement already satisfied: filelock in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (3.20.3)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (2026.1.0)\n",
                        "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (1.2.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (0.28.1)\n",
                        "Requirement already satisfied: packaging>=20.9 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (25.0)\n",
                        "Requirement already satisfied: shellingham in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (1.5.4)\n",
                        "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (4.67.2)\n",
                        "Requirement already satisfied: typer-slim in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from huggingface-hub) (0.21.1)\n",
                        "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-core) (1.33)\n",
                        "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-core) (0.14.0)\n",
                        "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
                        "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
                        "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
                        "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
                        "Requirement already satisfied: anyio in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub) (4.12.1)\n",
                        "Requirement already satisfied: certifi in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub) (2026.1.4)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub) (1.0.9)\n",
                        "Requirement already satisfied: idna in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub) (3.11)\n",
                        "Requirement already satisfied: h11>=0.16 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub) (0.16.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.3)\n",
                        "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
                        "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
                        "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
                        "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
                        "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
                        "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
                        "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
                        "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
                        "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
                        "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.6.3)\n",
                        "Requirement already satisfied: colorama in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub) (0.4.6)\n",
                        "Requirement already satisfied: click>=8.0.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from typer-slim->huggingface-hub) (8.3.1)\n",
                        "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
                        "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nicol\\desktop\\progetti\\pysofa\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 24.0 -> 26.0\n",
                        "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
                    ]
                }
            ],
            "source": [
                "INSTALL_MODEL_LIBRARY = False\n",
                "\n",
                "if INSTALL_MODEL_LIBRARY:\n",
                "    !pip install llama-cpp-python langchain langchain-community langchain-experimental sqlalchemy huggingface-hub langchain-core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "import os\n",
                "import logging\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "\n",
                "# Aggiungiamo la root del progetto al path per importare db_module\n",
                "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
                "import db_module\n",
                "\n",
                "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Esplorazione Struttura Database\n",
                "Visualizza lo schema delle tabelle e i dati reali per comprendere la struttura."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tabelle trovate nel DB: ['match_graphics_column', 'match_statistics_column', 'matches']\n",
                        "\n",
                        "========================================\n",
                        " TABELLA: match_graphics_column\n",
                        "========================================\n",
                        "\n",
                        "[SCHEMA COLONNE]\n",
                        "  - match_id             | Type: BIGINT\n",
                        "  - possession_1         | Type: DOUBLE PRECISION\n",
                        "  - possession_2         | Type: DOUBLE PRECISION\n",
                        "  - possession_3         | Type: DOUBLE PRECISION\n",
                        "  - possession_4         | Type: DOUBLE PRECISION\n",
                        "  - possession_5         | Type: DOUBLE PRECISION\n",
                        "  - possession_6         | Type: DOUBLE PRECISION\n",
                        "  - possession_7         | Type: DOUBLE PRECISION\n",
                        "  - possession_8         | Type: DOUBLE PRECISION\n",
                        "  - possession_9         | Type: DOUBLE PRECISION\n",
                        "  - possession_10        | Type: DOUBLE PRECISION\n",
                        "  - possession_11        | Type: DOUBLE PRECISION\n",
                        "  - possession_12        | Type: DOUBLE PRECISION\n",
                        "  - possession_13        | Type: DOUBLE PRECISION\n",
                        "  - possession_14        | Type: DOUBLE PRECISION\n",
                        "  - possession_15        | Type: DOUBLE PRECISION\n",
                        "  - possession_16        | Type: DOUBLE PRECISION\n",
                        "  - possession_17        | Type: DOUBLE PRECISION\n",
                        "  - possession_18        | Type: DOUBLE PRECISION\n",
                        "  - possession_19        | Type: DOUBLE PRECISION\n",
                        "  - possession_20        | Type: DOUBLE PRECISION\n",
                        "  - possession_21        | Type: DOUBLE PRECISION\n",
                        "  - possession_22        | Type: DOUBLE PRECISION\n",
                        "  - possession_23        | Type: DOUBLE PRECISION\n",
                        "  - possession_24        | Type: DOUBLE PRECISION\n",
                        "  - possession_25        | Type: DOUBLE PRECISION\n",
                        "  - possession_26        | Type: DOUBLE PRECISION\n",
                        "  - possession_27        | Type: DOUBLE PRECISION\n",
                        "  - possession_28        | Type: DOUBLE PRECISION\n",
                        "  - possession_29        | Type: DOUBLE PRECISION\n",
                        "  - possession_30        | Type: DOUBLE PRECISION\n",
                        "  - possession_31        | Type: DOUBLE PRECISION\n",
                        "  - possession_32        | Type: DOUBLE PRECISION\n",
                        "  - possession_33        | Type: DOUBLE PRECISION\n",
                        "  - possession_34        | Type: DOUBLE PRECISION\n",
                        "  - possession_35        | Type: DOUBLE PRECISION\n",
                        "  - possession_36        | Type: DOUBLE PRECISION\n",
                        "  - possession_37        | Type: DOUBLE PRECISION\n",
                        "  - possession_38        | Type: DOUBLE PRECISION\n",
                        "  - possession_39        | Type: DOUBLE PRECISION\n",
                        "  - possession_40        | Type: DOUBLE PRECISION\n",
                        "  - possession_41        | Type: DOUBLE PRECISION\n",
                        "  - possession_42        | Type: DOUBLE PRECISION\n",
                        "  - possession_43        | Type: DOUBLE PRECISION\n",
                        "  - possession_44        | Type: DOUBLE PRECISION\n",
                        "  - possession_45        | Type: DOUBLE PRECISION\n",
                        "  - possession_46        | Type: DOUBLE PRECISION\n",
                        "  - possession_47        | Type: DOUBLE PRECISION\n",
                        "  - possession_48        | Type: DOUBLE PRECISION\n",
                        "  - possession_49        | Type: DOUBLE PRECISION\n",
                        "  - possession_50        | Type: DOUBLE PRECISION\n",
                        "  - possession_51        | Type: DOUBLE PRECISION\n",
                        "  - possession_52        | Type: DOUBLE PRECISION\n",
                        "  - possession_53        | Type: DOUBLE PRECISION\n",
                        "  - possession_54        | Type: DOUBLE PRECISION\n",
                        "  - possession_55        | Type: DOUBLE PRECISION\n",
                        "  - possession_56        | Type: DOUBLE PRECISION\n",
                        "  - possession_57        | Type: DOUBLE PRECISION\n",
                        "  - possession_58        | Type: DOUBLE PRECISION\n",
                        "  - possession_59        | Type: DOUBLE PRECISION\n",
                        "  - possession_60        | Type: DOUBLE PRECISION\n",
                        "  - possession_61        | Type: DOUBLE PRECISION\n",
                        "  - possession_62        | Type: DOUBLE PRECISION\n",
                        "  - possession_63        | Type: DOUBLE PRECISION\n",
                        "  - possession_64        | Type: DOUBLE PRECISION\n",
                        "  - possession_65        | Type: DOUBLE PRECISION\n",
                        "  - possession_66        | Type: DOUBLE PRECISION\n",
                        "  - possession_67        | Type: DOUBLE PRECISION\n",
                        "  - possession_68        | Type: DOUBLE PRECISION\n",
                        "  - possession_69        | Type: DOUBLE PRECISION\n",
                        "  - possession_70        | Type: DOUBLE PRECISION\n",
                        "  - possession_71        | Type: DOUBLE PRECISION\n",
                        "  - possession_72        | Type: DOUBLE PRECISION\n",
                        "  - possession_73        | Type: DOUBLE PRECISION\n",
                        "  - possession_74        | Type: DOUBLE PRECISION\n",
                        "  - possession_75        | Type: DOUBLE PRECISION\n",
                        "  - possession_76        | Type: DOUBLE PRECISION\n",
                        "  - possession_77        | Type: DOUBLE PRECISION\n",
                        "  - possession_78        | Type: DOUBLE PRECISION\n",
                        "  - possession_79        | Type: DOUBLE PRECISION\n",
                        "  - possession_80        | Type: DOUBLE PRECISION\n",
                        "  - possession_81        | Type: DOUBLE PRECISION\n",
                        "  - possession_82        | Type: DOUBLE PRECISION\n",
                        "  - possession_83        | Type: DOUBLE PRECISION\n",
                        "  - possession_84        | Type: DOUBLE PRECISION\n",
                        "  - possession_85        | Type: DOUBLE PRECISION\n",
                        "  - possession_86        | Type: DOUBLE PRECISION\n",
                        "  - possession_87        | Type: DOUBLE PRECISION\n",
                        "  - possession_88        | Type: DOUBLE PRECISION\n",
                        "  - possession_89        | Type: DOUBLE PRECISION\n",
                        "  - possession_90        | Type: DOUBLE PRECISION\n",
                        "\n",
                        "[ANTEPRIMA DATI - Prime 10 righe]\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>match_id</th>\n",
                            "      <th>possession_1</th>\n",
                            "      <th>possession_2</th>\n",
                            "      <th>possession_3</th>\n",
                            "      <th>possession_4</th>\n",
                            "      <th>possession_5</th>\n",
                            "      <th>possession_6</th>\n",
                            "      <th>possession_7</th>\n",
                            "      <th>possession_8</th>\n",
                            "      <th>possession_9</th>\n",
                            "      <th>...</th>\n",
                            "      <th>possession_81</th>\n",
                            "      <th>possession_82</th>\n",
                            "      <th>possession_83</th>\n",
                            "      <th>possession_84</th>\n",
                            "      <th>possession_85</th>\n",
                            "      <th>possession_86</th>\n",
                            "      <th>possession_87</th>\n",
                            "      <th>possession_88</th>\n",
                            "      <th>possession_89</th>\n",
                            "      <th>possession_90</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>-2.0</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>-21.0</td>\n",
                            "      <td>-6.0</td>\n",
                            "      <td>12.0</td>\n",
                            "      <td>51.0</td>\n",
                            "      <td>32.0</td>\n",
                            "      <td>23.0</td>\n",
                            "      <td>19.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-6.0</td>\n",
                            "      <td>-9.0</td>\n",
                            "      <td>-7.0</td>\n",
                            "      <td>-2.0</td>\n",
                            "      <td>11.0</td>\n",
                            "      <td>18.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>-7.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>12.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>12436502</td>\n",
                            "      <td>-2.0</td>\n",
                            "      <td>-3.0</td>\n",
                            "      <td>-4.0</td>\n",
                            "      <td>-25.0</td>\n",
                            "      <td>-8.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>26.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-14.0</td>\n",
                            "      <td>-39.0</td>\n",
                            "      <td>-26.0</td>\n",
                            "      <td>-18.0</td>\n",
                            "      <td>-12.0</td>\n",
                            "      <td>-55.0</td>\n",
                            "      <td>-28.0</td>\n",
                            "      <td>-79.0</td>\n",
                            "      <td>-58.0</td>\n",
                            "      <td>49.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>12436503</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>54.0</td>\n",
                            "      <td>67.0</td>\n",
                            "      <td>40.0</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>17.0</td>\n",
                            "      <td>26.0</td>\n",
                            "      <td>15.0</td>\n",
                            "      <td>11.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-12.0</td>\n",
                            "      <td>-15.0</td>\n",
                            "      <td>-17.0</td>\n",
                            "      <td>-23.0</td>\n",
                            "      <td>-54.0</td>\n",
                            "      <td>-50.0</td>\n",
                            "      <td>-62.0</td>\n",
                            "      <td>-41.0</td>\n",
                            "      <td>-32.0</td>\n",
                            "      <td>-26.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>12436922</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-10.0</td>\n",
                            "      <td>-65.0</td>\n",
                            "      <td>-39.0</td>\n",
                            "      <td>-33.0</td>\n",
                            "      <td>34.0</td>\n",
                            "      <td>15.0</td>\n",
                            "      <td>17.0</td>\n",
                            "      <td>-42.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>32.0</td>\n",
                            "      <td>20.0</td>\n",
                            "      <td>12.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>-8.0</td>\n",
                            "      <td>-4.0</td>\n",
                            "      <td>-5.0</td>\n",
                            "      <td>-58.0</td>\n",
                            "      <td>-39.0</td>\n",
                            "      <td>-9.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>12436914</td>\n",
                            "      <td>-6.0</td>\n",
                            "      <td>-9.0</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>-6.0</td>\n",
                            "      <td>-6.0</td>\n",
                            "      <td>-20.0</td>\n",
                            "      <td>-42.0</td>\n",
                            "      <td>-62.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>21.0</td>\n",
                            "      <td>38.0</td>\n",
                            "      <td>23.0</td>\n",
                            "      <td>34.0</td>\n",
                            "      <td>24.0</td>\n",
                            "      <td>14.0</td>\n",
                            "      <td>19.0</td>\n",
                            "      <td>14.0</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>24.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>12436498</td>\n",
                            "      <td>-11.0</td>\n",
                            "      <td>-13.0</td>\n",
                            "      <td>-22.0</td>\n",
                            "      <td>-22.0</td>\n",
                            "      <td>19.0</td>\n",
                            "      <td>12.0</td>\n",
                            "      <td>15.0</td>\n",
                            "      <td>46.0</td>\n",
                            "      <td>23.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>16.0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>47.0</td>\n",
                            "      <td>30.0</td>\n",
                            "      <td>19.0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>20.0</td>\n",
                            "      <td>-30.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>12436505</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>13.0</td>\n",
                            "      <td>60.0</td>\n",
                            "      <td>43.0</td>\n",
                            "      <td>33.0</td>\n",
                            "      <td>27.0</td>\n",
                            "      <td>25.0</td>\n",
                            "      <td>19.0</td>\n",
                            "      <td>18.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>13.0</td>\n",
                            "      <td>-6.0</td>\n",
                            "      <td>-5.0</td>\n",
                            "      <td>-4.0</td>\n",
                            "      <td>-58.0</td>\n",
                            "      <td>-30.0</td>\n",
                            "      <td>33.0</td>\n",
                            "      <td>15.0</td>\n",
                            "      <td>14.0</td>\n",
                            "      <td>13.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>12436507</td>\n",
                            "      <td>-2.0</td>\n",
                            "      <td>45.0</td>\n",
                            "      <td>49.0</td>\n",
                            "      <td>30.0</td>\n",
                            "      <td>17.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>-15.0</td>\n",
                            "      <td>-24.0</td>\n",
                            "      <td>24.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-29.0</td>\n",
                            "      <td>-9.0</td>\n",
                            "      <td>10.0</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>16.0</td>\n",
                            "      <td>16.0</td>\n",
                            "      <td>14.0</td>\n",
                            "      <td>20.0</td>\n",
                            "      <td>42.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>12436504</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>11.0</td>\n",
                            "      <td>14.0</td>\n",
                            "      <td>20.0</td>\n",
                            "      <td>10.0</td>\n",
                            "      <td>41.0</td>\n",
                            "      <td>26.0</td>\n",
                            "      <td>17.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-8.0</td>\n",
                            "      <td>-32.0</td>\n",
                            "      <td>-20.0</td>\n",
                            "      <td>-11.0</td>\n",
                            "      <td>-6.0</td>\n",
                            "      <td>-43.0</td>\n",
                            "      <td>-55.0</td>\n",
                            "      <td>-27.0</td>\n",
                            "      <td>-20.0</td>\n",
                            "      <td>26.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>12504681</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>12.0</td>\n",
                            "      <td>14.0</td>\n",
                            "      <td>41.0</td>\n",
                            "      <td>29.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>10.0</td>\n",
                            "      <td>20.0</td>\n",
                            "      <td>24.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>51.0</td>\n",
                            "      <td>22.0</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>13.0</td>\n",
                            "      <td>41.0</td>\n",
                            "      <td>58.0</td>\n",
                            "      <td>44.0</td>\n",
                            "      <td>33.0</td>\n",
                            "      <td>-11.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>10 rows Ã— 91 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   match_id  possession_1  possession_2  possession_3  possession_4  \\\n",
                            "0  12436500          -2.0           3.0         -21.0          -6.0   \n",
                            "1  12436502          -2.0          -3.0          -4.0         -25.0   \n",
                            "2  12436503           5.0          54.0          67.0          40.0   \n",
                            "3  12436922          -1.0         -10.0         -65.0         -39.0   \n",
                            "4  12436914          -6.0          -9.0           8.0           2.0   \n",
                            "5  12436498         -11.0         -13.0         -22.0         -22.0   \n",
                            "6  12436505           8.0          13.0          60.0          43.0   \n",
                            "7  12436507          -2.0          45.0          49.0          30.0   \n",
                            "8  12436504           6.0           9.0          11.0          14.0   \n",
                            "9  12504681           9.0          12.0          14.0          41.0   \n",
                            "\n",
                            "   possession_5  possession_6  possession_7  possession_8  possession_9  ...  \\\n",
                            "0          12.0          51.0          32.0          23.0          19.0  ...   \n",
                            "1          -8.0          -1.0           4.0           6.0          26.0  ...   \n",
                            "2           9.0          17.0          26.0          15.0          11.0  ...   \n",
                            "3         -33.0          34.0          15.0          17.0         -42.0  ...   \n",
                            "4          -6.0          -6.0         -20.0         -42.0         -62.0  ...   \n",
                            "5          19.0          12.0          15.0          46.0          23.0  ...   \n",
                            "6          33.0          27.0          25.0          19.0          18.0  ...   \n",
                            "7          17.0           7.0         -15.0         -24.0          24.0  ...   \n",
                            "8          20.0          10.0          41.0          26.0          17.0  ...   \n",
                            "9          29.0           7.0          10.0          20.0          24.0  ...   \n",
                            "\n",
                            "   possession_81  possession_82  possession_83  possession_84  possession_85  \\\n",
                            "0           -6.0           -9.0           -7.0           -2.0           11.0   \n",
                            "1          -14.0          -39.0          -26.0          -18.0          -12.0   \n",
                            "2          -12.0          -15.0          -17.0          -23.0          -54.0   \n",
                            "3           32.0           20.0           12.0            7.0           -8.0   \n",
                            "4           21.0           38.0           23.0           34.0           24.0   \n",
                            "5            6.0           16.0            5.0           47.0           30.0   \n",
                            "6           13.0           -6.0           -5.0           -4.0          -58.0   \n",
                            "7          -29.0           -9.0           10.0            8.0           16.0   \n",
                            "8           -8.0          -32.0          -20.0          -11.0           -6.0   \n",
                            "9            6.0           51.0           22.0            8.0           13.0   \n",
                            "\n",
                            "   possession_86  possession_87  possession_88  possession_89  possession_90  \n",
                            "0           18.0            7.0           -7.0            7.0           12.0  \n",
                            "1          -55.0          -28.0          -79.0          -58.0           49.0  \n",
                            "2          -50.0          -62.0          -41.0          -32.0          -26.0  \n",
                            "3           -4.0           -5.0          -58.0          -39.0           -9.0  \n",
                            "4           14.0           19.0           14.0            9.0           24.0  \n",
                            "5           19.0            5.0            4.0           20.0          -30.0  \n",
                            "6          -30.0           33.0           15.0           14.0           13.0  \n",
                            "7           16.0           14.0           20.0           42.0           -1.0  \n",
                            "8          -43.0          -55.0          -27.0          -20.0           26.0  \n",
                            "9           41.0           58.0           44.0           33.0          -11.0  \n",
                            "\n",
                            "[10 rows x 91 columns]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "========================================\n",
                        " TABELLA: match_statistics_column\n",
                        "========================================\n",
                        "\n",
                        "[SCHEMA COLONNE]\n",
                        "  - match_id             | Type: BIGINT\n",
                        "  - period               | Type: TEXT\n",
                        "  - groupname            | Type: TEXT\n",
                        "  - name                 | Type: TEXT\n",
                        "  - home                 | Type: TEXT\n",
                        "  - away                 | Type: TEXT\n",
                        "  - comparecode          | Type: INTEGER\n",
                        "  - statisticstype       | Type: TEXT\n",
                        "  - valuetype            | Type: TEXT\n",
                        "  - homevalue            | Type: DOUBLE PRECISION\n",
                        "  - awayvalue            | Type: DOUBLE PRECISION\n",
                        "  - rendertype           | Type: INTEGER\n",
                        "  - key                  | Type: TEXT\n",
                        "\n",
                        "[ANTEPRIMA DATI - Prime 10 righe]\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>match_id</th>\n",
                            "      <th>period</th>\n",
                            "      <th>groupname</th>\n",
                            "      <th>name</th>\n",
                            "      <th>home</th>\n",
                            "      <th>away</th>\n",
                            "      <th>comparecode</th>\n",
                            "      <th>statisticstype</th>\n",
                            "      <th>valuetype</th>\n",
                            "      <th>homevalue</th>\n",
                            "      <th>awayvalue</th>\n",
                            "      <th>rendertype</th>\n",
                            "      <th>key</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Ball possession</td>\n",
                            "      <td>60%</td>\n",
                            "      <td>40%</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>60.0</td>\n",
                            "      <td>40.00</td>\n",
                            "      <td>2</td>\n",
                            "      <td>ballPossession</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Expected goals</td>\n",
                            "      <td>2.40</td>\n",
                            "      <td>1.06</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>2.4</td>\n",
                            "      <td>1.06</td>\n",
                            "      <td>1</td>\n",
                            "      <td>expectedGoals</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Big chances</td>\n",
                            "      <td>4</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>bigChanceCreated</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Total shots</td>\n",
                            "      <td>13</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>13.0</td>\n",
                            "      <td>7.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>totalShotsOnGoal</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Goalkeeper saves</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>3</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>goalkeeperSaves</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Corner kicks</td>\n",
                            "      <td>5</td>\n",
                            "      <td>4</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>cornerKicks</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Fouls</td>\n",
                            "      <td>9</td>\n",
                            "      <td>10</td>\n",
                            "      <td>2</td>\n",
                            "      <td>negative</td>\n",
                            "      <td>event</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>10.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>fouls</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Passes</td>\n",
                            "      <td>576</td>\n",
                            "      <td>378</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>576.0</td>\n",
                            "      <td>378.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>passes</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Tackles</td>\n",
                            "      <td>20</td>\n",
                            "      <td>15</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>20.0</td>\n",
                            "      <td>15.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>totalTackle</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>12436500</td>\n",
                            "      <td>ALL</td>\n",
                            "      <td>Match overview</td>\n",
                            "      <td>Free kicks</td>\n",
                            "      <td>10</td>\n",
                            "      <td>9</td>\n",
                            "      <td>1</td>\n",
                            "      <td>positive</td>\n",
                            "      <td>event</td>\n",
                            "      <td>10.0</td>\n",
                            "      <td>9.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>freeKicks</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   match_id period       groupname              name  home  away  comparecode  \\\n",
                            "0  12436500    ALL  Match overview   Ball possession   60%   40%            1   \n",
                            "1  12436500    ALL  Match overview    Expected goals  2.40  1.06            1   \n",
                            "2  12436500    ALL  Match overview       Big chances     4     1            1   \n",
                            "3  12436500    ALL  Match overview       Total shots    13     7            1   \n",
                            "4  12436500    ALL  Match overview  Goalkeeper saves     2     2            3   \n",
                            "5  12436500    ALL  Match overview      Corner kicks     5     4            1   \n",
                            "6  12436500    ALL  Match overview             Fouls     9    10            2   \n",
                            "7  12436500    ALL  Match overview            Passes   576   378            1   \n",
                            "8  12436500    ALL  Match overview           Tackles    20    15            1   \n",
                            "9  12436500    ALL  Match overview        Free kicks    10     9            1   \n",
                            "\n",
                            "  statisticstype valuetype  homevalue  awayvalue  rendertype               key  \n",
                            "0       positive     event       60.0      40.00           2    ballPossession  \n",
                            "1       positive     event        2.4       1.06           1     expectedGoals  \n",
                            "2       positive     event        4.0       1.00           1  bigChanceCreated  \n",
                            "3       positive     event       13.0       7.00           1  totalShotsOnGoal  \n",
                            "4       positive     event        2.0       2.00           1   goalkeeperSaves  \n",
                            "5       positive     event        5.0       4.00           1       cornerKicks  \n",
                            "6       negative     event        9.0      10.00           1             fouls  \n",
                            "7       positive     event      576.0     378.00           1            passes  \n",
                            "8       positive     event       20.0      15.00           1       totalTackle  \n",
                            "9       positive     event       10.0       9.00           1         freeKicks  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "========================================\n",
                        " TABELLA: matches\n",
                        "========================================\n",
                        "\n",
                        "[SCHEMA COLONNE]\n",
                        "  - id                   | Type: BIGINT\n",
                        "  - tournament           | Type: TEXT\n",
                        "  - season               | Type: TEXT\n",
                        "  - home_team            | Type: TEXT\n",
                        "  - away_team            | Type: TEXT\n",
                        "  - home_score           | Type: TEXT\n",
                        "  - away_score           | Type: TEXT\n",
                        "  - status               | Type: TEXT\n",
                        "  - start_timestamp      | Type: BIGINT\n",
                        "  - home_country         | Type: TEXT\n",
                        "  - away_country         | Type: TEXT\n",
                        "\n",
                        "[ANTEPRIMA DATI - Prime 10 righe]\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>tournament</th>\n",
                            "      <th>season</th>\n",
                            "      <th>home_team</th>\n",
                            "      <th>away_team</th>\n",
                            "      <th>home_score</th>\n",
                            "      <th>away_score</th>\n",
                            "      <th>status</th>\n",
                            "      <th>start_timestamp</th>\n",
                            "      <th>home_country</th>\n",
                            "      <th>away_country</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>12436498</td>\n",
                            "      <td>Premier League</td>\n",
                            "      <td>Premier League 24/25</td>\n",
                            "      <td>Chelsea</td>\n",
                            "      <td>Aston Villa</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733059800</td>\n",
                            "      <td>England</td>\n",
                            "      <td>England</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>12436505</td>\n",
                            "      <td>Premier League</td>\n",
                            "      <td>Premier League 24/25</td>\n",
                            "      <td>Manchester United</td>\n",
                            "      <td>Everton</td>\n",
                            "      <td>4</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733059800</td>\n",
                            "      <td>England</td>\n",
                            "      <td>England</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>12436507</td>\n",
                            "      <td>Premier League</td>\n",
                            "      <td>Premier League 24/25</td>\n",
                            "      <td>Tottenham Hotspur</td>\n",
                            "      <td>Fulham</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733059800</td>\n",
                            "      <td>England</td>\n",
                            "      <td>England</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>12436504</td>\n",
                            "      <td>Premier League</td>\n",
                            "      <td>Premier League 24/25</td>\n",
                            "      <td>Liverpool</td>\n",
                            "      <td>Manchester City</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733068800</td>\n",
                            "      <td>England</td>\n",
                            "      <td>England</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>12504665</td>\n",
                            "      <td>Serie A</td>\n",
                            "      <td>Serie A 24/25</td>\n",
                            "      <td>Udinese</td>\n",
                            "      <td>Genoa</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733052600</td>\n",
                            "      <td>Italy</td>\n",
                            "      <td>Italy</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>12504666</td>\n",
                            "      <td>Serie A</td>\n",
                            "      <td>Serie A 24/25</td>\n",
                            "      <td>Parma</td>\n",
                            "      <td>Lazio</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733061600</td>\n",
                            "      <td>Italy</td>\n",
                            "      <td>Italy</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>12504669</td>\n",
                            "      <td>Serie A</td>\n",
                            "      <td>Serie A 24/25</td>\n",
                            "      <td>Torino</td>\n",
                            "      <td>Napoli</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733061600</td>\n",
                            "      <td>Italy</td>\n",
                            "      <td>Italy</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>12504674</td>\n",
                            "      <td>Serie A</td>\n",
                            "      <td>Serie A 24/25</td>\n",
                            "      <td>Lecce</td>\n",
                            "      <td>Juventus</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733082300</td>\n",
                            "      <td>Italy</td>\n",
                            "      <td>Italy</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>12504673</td>\n",
                            "      <td>Serie A</td>\n",
                            "      <td>Serie A 24/25</td>\n",
                            "      <td>Roma</td>\n",
                            "      <td>Atalanta</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733168700</td>\n",
                            "      <td>Italy</td>\n",
                            "      <td>Italy</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>12437727</td>\n",
                            "      <td>LaLiga</td>\n",
                            "      <td>LaLiga 24/25</td>\n",
                            "      <td>Villarreal</td>\n",
                            "      <td>Girona FC</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>Ended</td>\n",
                            "      <td>1733058000</td>\n",
                            "      <td>Spain</td>\n",
                            "      <td>Spain</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         id      tournament                season          home_team  \\\n",
                            "0  12436498  Premier League  Premier League 24/25            Chelsea   \n",
                            "1  12436505  Premier League  Premier League 24/25  Manchester United   \n",
                            "2  12436507  Premier League  Premier League 24/25  Tottenham Hotspur   \n",
                            "3  12436504  Premier League  Premier League 24/25          Liverpool   \n",
                            "4  12504665         Serie A         Serie A 24/25            Udinese   \n",
                            "5  12504666         Serie A         Serie A 24/25              Parma   \n",
                            "6  12504669         Serie A         Serie A 24/25             Torino   \n",
                            "7  12504674         Serie A         Serie A 24/25              Lecce   \n",
                            "8  12504673         Serie A         Serie A 24/25               Roma   \n",
                            "9  12437727          LaLiga          LaLiga 24/25         Villarreal   \n",
                            "\n",
                            "         away_team home_score away_score status  start_timestamp home_country  \\\n",
                            "0      Aston Villa          3          0  Ended       1733059800      England   \n",
                            "1          Everton          4          0  Ended       1733059800      England   \n",
                            "2           Fulham          1          1  Ended       1733059800      England   \n",
                            "3  Manchester City          2          0  Ended       1733068800      England   \n",
                            "4            Genoa          0          2  Ended       1733052600        Italy   \n",
                            "5            Lazio          3          1  Ended       1733061600        Italy   \n",
                            "6           Napoli          0          1  Ended       1733061600        Italy   \n",
                            "7         Juventus          1          1  Ended       1733082300        Italy   \n",
                            "8         Atalanta          0          2  Ended       1733168700        Italy   \n",
                            "9        Girona FC          2          2  Ended       1733058000        Spain   \n",
                            "\n",
                            "  away_country  \n",
                            "0      England  \n",
                            "1      England  \n",
                            "2      England  \n",
                            "3      England  \n",
                            "4        Italy  \n",
                            "5        Italy  \n",
                            "6        Italy  \n",
                            "7        Italy  \n",
                            "8        Italy  \n",
                            "9        Spain  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from sqlalchemy import create_engine, inspect\n",
                "\n",
                "# Creazione connessione diretta per ispezione\n",
                "db_uri = \"postgresql+psycopg2://postgres:postgres@localhost:5432/football_db\"\n",
                "engine = create_engine(db_uri)\n",
                "inspector = inspect(engine)\n",
                "\n",
                "# Ottieni lista tabelle\n",
                "tables = [t for t in inspector.get_table_names() if not t.endswith('_json')]\n",
                "print(f\"Tabelle trovate nel DB: {tables}\")\n",
                "\n",
                "for table in tables:\n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\" TABELLA: {table}\")\n",
                "    print(f\"{'='*40}\")\n",
                "    \n",
                "    # 1. Stampa Info Colonne (Nome e Tipo)\n",
                "    print(\"\\n[SCHEMA COLONNE]\")\n",
                "    columns_info = inspector.get_columns(table)\n",
                "    for col in columns_info:\n",
                "        print(f\"  - {col['name']:<20} | Type: {col['type']}\")\n",
                "    \n",
                "    # 2. Stampa Prime 10 Righe\n",
                "    print(\"\\n[ANTEPRIMA DATI - Prime 10 righe]\")\n",
                "    try:\n",
                "        df_preview = pd.read_sql(f\"SELECT * FROM {table} LIMIT 10\", engine)\n",
                "        display(df_preview)\n",
                "    except Exception as e:\n",
                "        print(f\"Errore nella lettura della tabella {table}: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "DOWNLOAD_MODEL = False\n",
                "RUN_NO_LLM_REQUEST = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Download Modello\n",
                "Esegui questa cella per scaricare un modello leggero (es. TinyLlama) da Hugging Face. VerrÃ  salvato nella cartella `models/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "if DOWNLOAD_MODEL:\n",
                "    from huggingface_hub import hf_hub_download\n",
                "    import os\n",
                "\n",
                "    # Creiamo la cartella models se non esiste\n",
                "    if not os.path.exists(\"models\"):\n",
                "        os.makedirs(\"models\")\n",
                "\n",
                "    print(\"Inizio download modello...\")\n",
                "    model_path = hf_hub_download(\n",
                "        repo_id=\"TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF\",\n",
                "        filename=\"tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\",\n",
                "        local_dir=\"models\",\n",
                "        local_dir_use_symlinks=False\n",
                ")\n",
                "    print(f\"Modello scaricato in: {model_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Inizializzazione LLM\n",
                "Configuriamo il modello e la catena SQL con un prompt che gestisca correttamente i tipi di dato."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_model_loader: loaded meta data with 23 key-value pairs and 201 tensors from models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf (version GGUF V3 (latest))\n",
                        "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
                        "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
                        "llama_model_loader: - kv   1:                               general.name str              = tinyllama_tinyllama-1.1b-chat-v1.0\n",
                        "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
                        "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 2048\n",
                        "llama_model_loader: - kv   4:                          llama.block_count u32              = 22\n",
                        "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5632\n",
                        "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 64\n",
                        "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
                        "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 4\n",
                        "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
                        "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
                        "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
                        "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
                        "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
                        "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
                        "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
                        "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,61249]   = [\"â– t\", \"e r\", \"i n\", \"â– a\", \"e n...\n",
                        "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
                        "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
                        "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
                        "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2\n",
                        "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% for message in messages %}\\n{% if m...\n",
                        "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
                        "llama_model_loader: - type  f32:   45 tensors\n",
                        "llama_model_loader: - type q4_K:  135 tensors\n",
                        "llama_model_loader: - type q6_K:   21 tensors\n",
                        "print_info: file format = GGUF V3 (latest)\n",
                        "print_info: file type   = Q4_K - Medium\n",
                        "print_info: file size   = 636.18 MiB (4.85 BPW) \n",
                        "init_tokenizer: initializing tokenizer for type 1\n",
                        "load: control token:      2 '</s>' is not marked as EOG\n",
                        "load: control token:      1 '<s>' is not marked as EOG\n",
                        "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
                        "load: printing all EOG tokens:\n",
                        "load:   - 2 ('</s>')\n",
                        "load: special tokens cache size = 3\n",
                        "load: token to piece cache size = 0.1684 MB\n",
                        "print_info: arch             = llama\n",
                        "print_info: vocab_only       = 0\n",
                        "print_info: n_ctx_train      = 2048\n",
                        "print_info: n_embd           = 2048\n",
                        "print_info: n_layer          = 22\n",
                        "print_info: n_head           = 32\n",
                        "print_info: n_head_kv        = 4\n",
                        "print_info: n_rot            = 64\n",
                        "print_info: n_swa            = 0\n",
                        "print_info: is_swa_any       = 0\n",
                        "print_info: n_embd_head_k    = 64\n",
                        "print_info: n_embd_head_v    = 64\n",
                        "print_info: n_gqa            = 8\n",
                        "print_info: n_embd_k_gqa     = 256\n",
                        "print_info: n_embd_v_gqa     = 256\n",
                        "print_info: f_norm_eps       = 0.0e+00\n",
                        "print_info: f_norm_rms_eps   = 1.0e-05\n",
                        "print_info: f_clamp_kqv      = 0.0e+00\n",
                        "print_info: f_max_alibi_bias = 0.0e+00\n",
                        "print_info: f_logit_scale    = 0.0e+00\n",
                        "print_info: f_attn_scale     = 0.0e+00\n",
                        "print_info: n_ff             = 5632\n",
                        "print_info: n_expert         = 0\n",
                        "print_info: n_expert_used    = 0\n",
                        "print_info: causal attn      = 1\n",
                        "print_info: pooling type     = 0\n",
                        "print_info: rope type        = 0\n",
                        "print_info: rope scaling     = linear\n",
                        "print_info: freq_base_train  = 10000.0\n",
                        "print_info: freq_scale_train = 1\n",
                        "print_info: n_ctx_orig_yarn  = 2048\n",
                        "print_info: rope_finetuned   = unknown\n",
                        "print_info: model type       = 1B\n",
                        "print_info: model params     = 1.10 B\n",
                        "print_info: general.name     = tinyllama_tinyllama-1.1b-chat-v1.0\n",
                        "print_info: vocab type       = SPM\n",
                        "print_info: n_vocab          = 32000\n",
                        "print_info: n_merges         = 0\n",
                        "print_info: BOS token        = 1 '<s>'\n",
                        "print_info: EOS token        = 2 '</s>'\n",
                        "print_info: UNK token        = 0 '<unk>'\n",
                        "print_info: PAD token        = 2 '</s>'\n",
                        "print_info: LF token         = 13 '<0x0A>'\n",
                        "print_info: EOG token        = 2 '</s>'\n",
                        "print_info: max token length = 48\n",
                        "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
                        "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
                        "load_tensors: tensor 'token_embd.weight' (q4_K) (and 66 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
                        "load_tensors:   CPU_REPACK model buffer size =   455.06 MiB\n",
                        "load_tensors:   CPU_Mapped model buffer size =   636.18 MiB\n",
                        "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.2.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.2.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.3.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.6.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.21.attn_v.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
                        "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",
                        ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
                        "..............\n",
                        "llama_context: constructing llama_context\n",
                        "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
                        "llama_context: n_seq_max     = 1\n",
                        "llama_context: n_ctx         = 4096\n",
                        "llama_context: n_ctx_per_seq = 4096\n",
                        "llama_context: n_batch       = 64\n",
                        "llama_context: n_ubatch      = 8\n",
                        "llama_context: causal_attn   = 1\n",
                        "llama_context: flash_attn    = 0\n",
                        "llama_context: kv_unified    = false\n",
                        "llama_context: freq_base     = 10000.0\n",
                        "llama_context: freq_scale    = 1\n",
                        "llama_context: n_ctx_per_seq (4096) > n_ctx_train (2048) -- possible training context overflow\n",
                        "set_abort_callback: call\n",
                        "llama_context:        CPU  output buffer size =     0.12 MiB\n",
                        "create_memory: n_ctx = 4096 (padded)\n",
                        "llama_kv_cache_unified: layer   0: dev = CPU\n",
                        "llama_kv_cache_unified: layer   1: dev = CPU\n",
                        "llama_kv_cache_unified: layer   2: dev = CPU\n",
                        "llama_kv_cache_unified: layer   3: dev = CPU\n",
                        "llama_kv_cache_unified: layer   4: dev = CPU\n",
                        "llama_kv_cache_unified: layer   5: dev = CPU\n",
                        "llama_kv_cache_unified: layer   6: dev = CPU\n",
                        "llama_kv_cache_unified: layer   7: dev = CPU\n",
                        "llama_kv_cache_unified: layer   8: dev = CPU\n",
                        "llama_kv_cache_unified: layer   9: dev = CPU\n",
                        "llama_kv_cache_unified: layer  10: dev = CPU\n",
                        "llama_kv_cache_unified: layer  11: dev = CPU\n",
                        "llama_kv_cache_unified: layer  12: dev = CPU\n",
                        "llama_kv_cache_unified: layer  13: dev = CPU\n",
                        "llama_kv_cache_unified: layer  14: dev = CPU\n",
                        "llama_kv_cache_unified: layer  15: dev = CPU\n",
                        "llama_kv_cache_unified: layer  16: dev = CPU\n",
                        "llama_kv_cache_unified: layer  17: dev = CPU\n",
                        "llama_kv_cache_unified: layer  18: dev = CPU\n",
                        "llama_kv_cache_unified: layer  19: dev = CPU\n",
                        "llama_kv_cache_unified: layer  20: dev = CPU\n",
                        "llama_kv_cache_unified: layer  21: dev = CPU\n",
                        "llama_kv_cache_unified:        CPU KV buffer size =    88.00 MiB\n",
                        "llama_kv_cache_unified: size =   88.00 MiB (  4096 cells,  22 layers,  1/1 seqs), K (f16):   44.00 MiB, V (f16):   44.00 MiB\n",
                        "llama_context: enumerating backends\n",
                        "llama_context: backend_ptrs.size() = 1\n",
                        "llama_context: max_nodes = 1608\n",
                        "llama_context: worst-case: n_tokens = 8, n_seqs = 1, n_outputs = 0\n",
                        "graph_reserve: reserving a graph for ubatch with n_tokens =    8, n_seqs =  1, n_outputs =    8\n",
                        "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
                        "graph_reserve: reserving a graph for ubatch with n_tokens =    8, n_seqs =  1, n_outputs =    8\n",
                        "llama_context:        CPU compute buffer size =     5.27 MiB\n",
                        "llama_context: graph nodes  = 776\n",
                        "llama_context: graph splits = 1\n",
                        "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
                        "Model metadata: {'general.name': 'tinyllama_tinyllama-1.1b-chat-v1.0', 'general.architecture': 'llama', 'llama.context_length': '2048', 'llama.rope.dimension_count': '64', 'llama.embedding_length': '2048', 'llama.block_count': '22', 'llama.feed_forward_length': '5632', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '15', 'llama.attention.head_count_kv': '4', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.chat_template': \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"}\n",
                        "Available chat formats from metadata: chat_template.default\n",
                        "Using gguf chat template: {% for message in messages %}\n",
                        "{% if message['role'] == 'user' %}\n",
                        "{{ '<|user|>\n",
                        "' + message['content'] + eos_token }}\n",
                        "{% elif message['role'] == 'system' %}\n",
                        "{{ '<|system|>\n",
                        "' + message['content'] + eos_token }}\n",
                        "{% elif message['role'] == 'assistant' %}\n",
                        "{{ '<|assistant|>\n",
                        "'  + message['content'] + eos_token }}\n",
                        "{% endif %}\n",
                        "{% if loop.last and add_generation_prompt %}\n",
                        "{{ '<|assistant|>' }}\n",
                        "{% endif %}\n",
                        "{% endfor %}\n",
                        "Using chat eos_token: </s>\n",
                        "Using chat bos_token: <s>\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.llms import LlamaCpp\n",
                "from langchain_community.utilities import SQLDatabase\n",
                "from langchain_experimental.sql import SQLDatabaseChain\n",
                "\n",
                "# LLM locale\n",
                "llm = LlamaCpp(\n",
                "    model_path=\"models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\", \n",
                "    n_ctx=4096,\n",
                "    temperature=0,\n",
                "    verbose=True\n",
                ")\n",
                "\n",
                "# Collegamento al DB PostgreSQL\n",
                "db = SQLDatabase.from_uri(\n",
                "    \"postgresql+psycopg2://postgres:postgres@localhost:5432/football_db\",\n",
                "    include_tables=['matches', 'match_statistics_column'],\n",
                "    sample_rows_in_table_info=2\n",
                ")\n",
                "\n",
                "# Definizione del Prompt con Esempi Few-Shot\n",
                "custom_prompt_template = \"\"\"You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run.\n",
                "\n",
                "The table 'matches' has the following columns: home_team, away_team, home_score, away_score, tournament, season.\n",
                "IMPORTANT: 'home_score' and 'away_score' are TEXT columns. \n",
                "For 'home_score' and 'away_score' columns, you MUST use CAST(NULLIF(col, 'N/A') AS INTEGER) for any math operations (SUM, +, -, AVG).\n",
                "\n",
                "Examples:\n",
                "Question: \"Total goals in all matches\"\n",
                "SQLQuery: SELECT SUM(CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) FROM matches\n",
                "SQLResult: Result of the SQLQuery\n",
                "\n",
                "Question: \"Matches with more than 3 goals\"\n",
                "SQLQuery: SELECT * FROM matches WHERE (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) > 3\n",
                "SQLResult: Result of the SQLQuery\n",
                "\n",
                "Only use the following tables:\n",
                "{table_info}\n",
                "\n",
                "Question: {input}\n",
                "SQLQuery:\"\"\"\n",
                "\n",
                "PROMPT = PromptTemplate(\n",
                "    input_variables=[\"input\", \"table_info\"],\n",
                "    template=custom_prompt_template\n",
                ")\n",
                "\n",
                "# Catena NL -> SQL\n",
                "sql_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Richieste LLM verbose\n",
                "Fai domande al database in linguaggio naturale."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_49104\\1593447863.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
                        "  risultato = sql_chain.run(query_nl)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
                        "Calculate the sum of all goals (home_score + away_score) in the table matches\n",
                        "SQLQuery:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =   15541.56 ms /   898 tokens (   17.31 ms per token,    57.78 tokens per second)\n",
                        "llama_perf_context_print:        eval time =    1930.23 ms /    49 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
                        "llama_perf_context_print:       total time =   17509.94 ms /   947 tokens\n",
                        "llama_perf_context_print:    graphs reused =        131\n",
                        "Llama.generate: 894 prefix-match hit, remaining 64 prompt tokens to eval\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT SUM(CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) FROM matches\u001b[0m\n",
                        "SQLResult: \u001b[33;1m\u001b[1;3m[(1663,)]\u001b[0m\n",
                        "Answer:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =    1086.25 ms /    64 tokens (   16.97 ms per token,    58.92 tokens per second)\n",
                        "llama_perf_context_print:        eval time =    2136.46 ms /    49 runs   (   43.60 ms per token,    22.94 tokens per second)\n",
                        "llama_perf_context_print:       total time =    3262.83 ms /   113 tokens\n",
                        "llama_perf_context_print:    graphs reused =         52\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT SUM(CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) FROM matches\u001b[0m\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n",
                        "\n",
                        "Risposta Finale: SELECT SUM(CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) FROM matches\n"
                    ]
                }
            ],
            "source": [
                "# Esempi di domande in linguaggio naturale\n",
                "query_nl = \"Calculate the sum of all goals (home_score + away_score) in the table matches\"\n",
                "\n",
                "try:\n",
                "    risultato = sql_chain.run(query_nl)\n",
                "    print(f\"\\nRisposta Finale: {risultato}\")\n",
                "except Exception as e:\n",
                "    print(f\"Errore nell'esecuzione della chain: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Richieste LLM per grafici\n",
                "Usa l'SQL generato dal LLM per creare grafici con Pandas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Llama.generate: 870 prefix-match hit, remaining 25 prompt tokens to eval\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
                        "Write only a SQL query to select tournament and home_team from matches limit 5\n",
                        "SQLQuery:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =     451.05 ms /    25 tokens (   18.04 ms per token,    55.43 tokens per second)\n",
                        "llama_perf_context_print:        eval time =     579.02 ms /    14 runs   (   41.36 ms per token,    24.18 tokens per second)\n",
                        "llama_perf_context_print:       total time =    1040.20 ms /    39 tokens\n",
                        "llama_perf_context_print:    graphs reused =         15\n",
                        "Llama.generate: 891 prefix-match hit, remaining 78 prompt tokens to eval\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT tournament, home_team FROM matches LIMIT 5\u001b[0m\n",
                        "SQLResult: \u001b[33;1m\u001b[1;3m[('Premier League', 'Chelsea'), ('Premier League', 'Manchester United'), ('Premier League', 'Tottenham Hotspur'), ('Premier League', 'Liverpool'), ('Serie A', 'Udinese')]\u001b[0m\n",
                        "Answer:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =    1933.55 ms /    78 tokens (   24.79 ms per token,    40.34 tokens per second)\n",
                        "llama_perf_context_print:        eval time =     648.98 ms /    14 runs   (   46.36 ms per token,    21.57 tokens per second)\n",
                        "llama_perf_context_print:       total time =    2593.78 ms /    92 tokens\n",
                        "llama_perf_context_print:    graphs reused =         19\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT tournament, home_team FROM matches LIMIT 5\u001b[0m\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n",
                        "SQL Generato (Raw): SELECT tournament, home_team FROM matches LIMIT 5\n"
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    sql_generated = sql_chain.run(\"Write only a SQL query to select tournament and home_team from matches limit 5\")\n",
                "    print(f\"SQL Generato (Raw): {sql_generated}\")\n",
                "except Exception as e:\n",
                "    print(f\"Errore: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Llama.generate: 870 prefix-match hit, remaining 29 prompt tokens to eval\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
                        "Mostrami le partite in cui c'Ã¨ stato un gol nei primi 20 minuti\n",
                        "SQLQuery:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =     597.53 ms /    29 tokens (   20.60 ms per token,    48.53 tokens per second)\n",
                        "llama_perf_context_print:        eval time =    6265.28 ms /   148 runs   (   42.33 ms per token,    23.62 tokens per second)\n",
                        "llama_perf_context_print:       total time =    7005.71 ms /   177 tokens\n",
                        "llama_perf_context_print:    graphs reused =        145\n",
                        "Llama.generate: 895 prefix-match hit, remaining 157 prompt tokens to eval\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT * FROM matches WHERE (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) > 3 AND (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER) < 10 AND (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER) > 20))\u001b[0m\n",
                        "SQLResult: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
                        "Answer:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =    2747.92 ms /   157 tokens (   17.50 ms per token,    57.13 tokens per second)\n",
                        "llama_perf_context_print:        eval time =    6191.97 ms /   148 runs   (   41.84 ms per token,    23.90 tokens per second)\n",
                        "llama_perf_context_print:       total time =    9075.19 ms /   305 tokens\n",
                        "llama_perf_context_print:    graphs reused =        156\n",
                        "Llama.generate: 870 prefix-match hit, remaining 28 prompt tokens to eval\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT * FROM matches WHERE (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) > 3 AND (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER) < 10 AND (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER) > 20))\u001b[0m\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n",
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
                        "Calculate the sum of all goals (home_score + away_score) in the table matches\n",
                        "SQLQuery:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =     459.48 ms /    28 tokens (   16.41 ms per token,    60.94 tokens per second)\n",
                        "llama_perf_context_print:        eval time =    1921.87 ms /    49 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
                        "llama_perf_context_print:       total time =    2418.41 ms /    77 tokens\n",
                        "llama_perf_context_print:    graphs reused =         49\n",
                        "Llama.generate: 894 prefix-match hit, remaining 64 prompt tokens to eval\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT SUM(CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) FROM matches\u001b[0m\n",
                        "SQLResult: \u001b[33;1m\u001b[1;3m[(1663,)]\u001b[0m\n",
                        "Answer:"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama_perf_context_print:        load time =   15541.76 ms\n",
                        "llama_perf_context_print: prompt eval time =    1168.43 ms /    64 tokens (   18.26 ms per token,    54.77 tokens per second)\n",
                        "llama_perf_context_print:        eval time =    2134.62 ms /    49 runs   (   43.56 ms per token,    22.95 tokens per second)\n",
                        "llama_perf_context_print:       total time =    3340.79 ms /   113 tokens\n",
                        "llama_perf_context_print:    graphs reused =         52\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32;1m\u001b[1;3mSELECT SUM(CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) FROM matches\u001b[0m\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n",
                        "SQL Generato (Raw): SELECT * FROM matches WHERE (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) > 3 AND (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER) < 10 AND (CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER) > 20))\n",
                        "\n",
                        "Risposta Finale: SELECT SUM(CAST(NULLIF(home_score, 'N/A') AS INTEGER) + CAST(NULLIF(away_score, 'N/A') AS INTEGER)) FROM matches\n"
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    sql_generated = sql_chain.run(\"Mostrami le partite in cui c'Ã¨ stato un gol nei primi 20 minuti\")\n",
                "    risultato = sql_chain.run(query_nl)\n",
                "    print(f\"SQL Generato (Raw): {sql_generated}\")\n",
                "    print(f\"\\nRisposta Finale: {risultato}\")\n",
                "except Exception as e:\n",
                "    print(f\"Errore: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Analisi e Visualizzazione Classica (Senza LLM)\n",
                "Se vuoi usare i filtri manuali invece del linguaggio naturale."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "RUN_CLASSIC = False\n",
                "if RUN_CLASSIC:\n",
                "    LEAGUE_FILTER = ['Serie A', 'Premier League']\n",
                "    SCORE_FILTER = []\n",
                "    \n",
                "    conn = db_module.create_connection()\n",
                "    query = \"SELECT home_score, away_score FROM matches\"\n",
                "    df_classic = pd.read_sql(query, conn)\n",
                "    conn.close()\n",
                "    print(f\"Caricati {len(df_classic)} match.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
